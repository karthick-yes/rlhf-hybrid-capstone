import networkx as nx
import numpy as np

class PreferenceGraph:
    """
    Preference Graph with Incremental Transitive Closure.
    
    Key Features:
    - Maintains DAG of preferences (winner -> loser)
    - Computes transitive closure INCREMENTALLY when edges are added
    - Tracks direct vs transitive edges for augmentation ratio
    """
    
    def __init__(self, capacity=10000):
        self.G = nx.DiGraph()
        self.capacity = capacity
        self.num_direct_queries = 0  # Human queries only
        self.num_auto_labels = 0      # UCB/LCB auto-labels
        self.num_transitive = 0       # Inferred via transitivity
        
    def add_preference(self, winner_id, loser_id, is_human_label=True, is_auto_label=False):
        """
        Add edge: winner -> loser with incremental transitive closure.
        
        Args:
            winner_id: ID of preferred trajectory
            loser_id: ID of less preferred trajectory
            is_human_label: True if from oracle query
            is_auto_label: True if from UCB/LCB filter
        """
        # Skip if edge already exists
        if self.G.has_edge(winner_id, loser_id):
            return
        
        # Add direct edge
        self.G.add_edge(winner_id, loser_id)
        
        # Track source
        if is_human_label:
            self.num_direct_queries += 1
        elif is_auto_label:
            self.num_auto_labels += 1
        
        # INCREMENTAL TRANSITIVE CLOSURE
        # Rule 1: If A > Winner and Winner > Loser, then A > Loser
        for predecessor in list(self.G.predecessors(winner_id)):
            if not self.G.has_edge(predecessor, loser_id):
                self.G.add_edge(predecessor, loser_id)
                self.num_transitive += 1
        
        # Rule 2: If Winner > Loser and Loser > B, then Winner > B
        for successor in list(self.G.successors(loser_id)):
            if not self.G.has_edge(winner_id, successor):
                self.G.add_edge(winner_id, successor)
                self.num_transitive += 1
        
        # Rule 3: If A > Winner and Loser > B, then A > B
        # (Combined rule from Rules 1 and 2)
        for predecessor in list(self.G.predecessors(winner_id)):
            for successor in list(self.G.successors(loser_id)):
                if not self.G.has_edge(predecessor, successor):
                    self.G.add_edge(predecessor, successor)
                    self.num_transitive += 1

    def get_stats(self):
        """
        Get augmentation statistics.
        
        Returns:
            direct: Number of direct queries (human)
            auto: Number of auto-labels (UCB/LCB)
            transitive: Number of inferred edges
            total: Total edges in graph
            augmentation_ratio: Total / Direct (auto-labels are FREE)
        """
        direct = self.num_direct_queries
        auto = self.num_auto_labels
        transitive = self.num_transitive
        total = self.G.number_of_edges()
        
        # FIXED: Augmentation ratio = Total / Human queries ONLY
        # Auto-labels are free (generated by ensemble), so don't count them
        ratio = total / direct if direct > 0 else 0.0
        
        return {
            'direct': direct,
            'auto': auto,
            'transitive': transitive,
            'total': total,
            'ratio': ratio
        }

    def get_training_pairs(self):
        """
        Return all preference pairs for training the reward model.
        Includes direct, auto-labeled, and transitive edges.
        
        Returns:
            List of (winner_id, loser_id) tuples
        """
        return list(self.G.edges())

    def get_defender(self):
        """
        Root Pairwise Strategy: Select the best node using PageRank.
        
        Returns:
            defender_id: ID of the current best trajectory
        """
        if len(self.G) == 0:
            return None
        
        try:
            # Reverse graph: edges go Loser -> Winner
            # Winners have high PageRank (many nodes point to them)
            rev_G = self.G.reverse()
            scores = nx.pagerank(rev_G)
            
            # Return node with highest score
            defender = max(scores, key=scores.get)
            return defender
            
        except Exception as e:
            # Fallback for disconnected graphs
            nodes = list(self.G.nodes())
            return nodes[0] if nodes else None
    
    def has_comparison(self, id1, id2):
        """
        Check if we already know the relationship between two trajectories.
        
        Returns:
            True if either (id1 > id2) or (id2 > id1) is in the graph
        """
        return self.G.has_edge(id1, id2) or self.G.has_edge(id2, id1)
    
    def get_win_counts(self, top_k=10):
        """
        Get win counts for top-k nodes (for debugging).
        
        Returns:
            List of (node_id, win_count) sorted by win count
        """
        win_counts = {}
        for node in self.G.nodes():
            win_counts[node] = self.G.out_degree(node)  # Number of nodes beaten
        
        sorted_counts = sorted(win_counts.items(), key=lambda x: x[1], reverse=True)
        return sorted_counts[:top_k]
    
    def print_summary(self):
        """Print human-readable summary of graph state"""
        stats = self.get_stats()
        
        print(f"\n{'='*60}")
        print(f"PREFERENCE GRAPH SUMMARY")
        print(f"{'='*60}")
        print(f"  Nodes (trajectories):     {self.G.number_of_nodes()}")
        print(f"  Direct queries (human):   {stats['direct']}")
        print(f"  Auto-labels (UCB/LCB):    {stats['auto']}")
        print(f"  Transitive inferences:    {stats['transitive']}")
        print(f"  Total edges:              {stats['total']}")
        print(f"  Augmentation ratio:       {stats['ratio']:.2f}x")
        print(f"{'='*60}\n")
        
        # Top winners
        top_winners = self.get_win_counts(5)
        if top_winners:
            print(f"Top 5 trajectories:")
            for rank, (node_id, wins) in enumerate(top_winners, 1):
                print(f"  {rank}. Trajectory {node_id}: {wins} wins")
            print()


# ==============================================================================
# UNIT TEST: Validate Incremental Closure
# ==============================================================================

def test_incremental_closure():
    """
    Test that incremental closure produces same result as full closure.
    """
    print("\n" + "="*70)
    print("TEST: Incremental Transitive Closure")
    print("="*70)
    
    graph = PreferenceGraph()
    
    # Add preferences: 5 > 3 > 1, 4 > 2 > 0
    edges = [
        (5, 3), (3, 1),  # Chain 1
        (4, 2), (2, 0),  # Chain 2
        (5, 4)           # Bridge: 5 > 4
    ]
    
    for winner, loser in edges:
        graph.add_preference(winner, loser, is_human_label=True)
    
    # Expected transitive edges:
    # From (5>3, 3>1): 5>1
    # From (4>2, 2>0): 4>0
    # From (5>4, 4>2): 5>2
    # From (5>4, 4>0): 5>0 (via 5>4>2>0)
    # From (5>3, 3>1, 5>4, 4>2, 2>0): ...
    
    stats = graph.get_stats()
    
    print(f"\nResults:")
    print(f"  Direct edges: {stats['direct']}")
    print(f"  Transitive edges: {stats['transitive']}")
    print(f"  Total edges: {stats['total']}")
    print(f"  Augmentation ratio: {stats['ratio']:.2f}x")
    
    # Verify specific edges exist
    expected_edges = [
        (5, 1),  # 5 > 3 > 1
        (4, 0),  # 4 > 2 > 0
        (5, 2),  # 5 > 4 > 2
        (5, 0),  # 5 > 4 > 2 > 0
    ]
    
    print(f"\nValidating transitive edges:")
    for w, l in expected_edges:
        exists = graph.G.has_edge(w, l)
        status = "PASS" if exists else "FAIL"
        print(f"  {w} > {l}: {status}")
    
    # Augmentation should be > 1.5x for this graph structure
    if stats['ratio'] > 1.5:
        print(f"\nPASS: Augmentation ratio {stats['ratio']:.2f}x > 1.5x")
    else:
        print(f"\nFAIL: Augmentation ratio {stats['ratio']:.2f}x < 1.5x")
    
    print("="*70 + "\n")


if __name__ == "__main__":
    test_incremental_closure()