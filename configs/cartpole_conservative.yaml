# ==================== ENVIRONMENT ====================
env_name: 'CartPole-v1'
state_dim: 4
action_dim: 1               # Continuous Proxy: Agent sees 1 dim [-1, 1]

# Episode lengths
segment_length: 50          # Query length: Clips shown for preference comparison
max_episode_steps: 500      # Collection length: Full episode rollout limit

# ==================== DUAL-AGENT LOOP ARCHITECTURE ====================
n_rounds: 5                 # Number of exploration-exploitation cycles
n_queries_per_round: 20     # Human queries per active learning phase
sac_steps_per_round: 10000   # SAC training steps per round
sac_collection_episodes: 10 # Episodes collected by SAC (exploitation)
entropy_collection_episodes: 10
entropy_decay: 0.95 # Episodes collected by Entropy (exploration)

# ==================== INITIAL WARMUP ====================
n_trajectories: 100         # Initial episodes (Entropy-only exploration)
n_bootstrap: 10             # Random queries to initialize ensemble

# ==================== ACTIVE LEARNING ====================
beta: 3.0                   # Revert to 3.0 to encourage auto-labeling
adaptive_beta: true         # Keep adaptive behavior
pool_size: 20               # Candidate pool size per query iteration
update_freq: 10             # Retrain ensemble every 10 queries

# ==================== REWARD ENSEMBLE ====================
ensemble_size: 7            # Number of reward models in ensemble
hidden_dim: 64              # Hidden layer size for reward networks
lr: 0.003                   # Faster learning rate for CartPole (was 0.0002)
weight_decay: 0.01     # L2 regularization

# ==================== SAC HYPERPARAMETERS ====================
gamma: 0.99                 # Discount factor
tau: 0.005                  # Target network update rate
alpha: 0.05                  # Entropy regularization

# ==================== BUFFERS ====================
buffer_capacity: 100000     # Maximum trajectory storage

# ==================== SAFETY & STABILITY ====================
min_warmup_reward: 20.0     # LOWERED: Prevent infinite loops in CartPole entropy
max_defender_uncertainty: 50.0 # Widen beta if defender Ïƒ exceeds this
exploration_epsilon: 0.1    # Random query probability
defender_reset_freq: 25     # PageRank validation frequency
std_threshold: 50.0         # NEW: Higher threshold for raw reward uncertainty

# ==================== DUAL-AGENT SPECIFIC ====================
entropy_full_buffer: true   # Knowledge sharing: true = thorough exploration

# ==================== REPRODUCIBILITY ====================
seed: 42